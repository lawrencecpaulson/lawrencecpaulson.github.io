---
layout: post
title:  "Memories: Edinburgh LCF, Cambridge LCF, HOL88"
usemathjax: true 
tags: [general, Robin Milner, MJC Gordon, LCF, HOL system]
---

Just over 40 years ago, 2 February 1982, I arrived at Heathrow to take up a postdoc under Mike Gordon and Robin Milner to work on Edinburgh LCF.
Mike kindly met me at the airport and drove me to a room that he had organised himself (favours which I have sadly never offered to any of my visitors).
This was the true start of my research career, leaving behind my offbeat PhD project
and ultimately reconnecting with ideas I had picked up from NG de Bruijn: the formalisation of mathematics.
Although I am best known for the development of Isabelle, most of my work in those early years went directly into the HOL system.

### Edinburgh LCF

LCF today is best known for its kernel architecture, described in a 
[previous post]({% post_url 2022-01-05-LCF %});
Talia Ringer has coined the expression *ephemeral proof objects* to describe the operation of its kernel, which never actually creates proof objects but could,
because the section of the code where proofs can be constructed is strictly confined.
Hardly anyone remembers the meaning of the acronym LCF: Logic for Computable Functions.
Edinburgh LCF was created in order to carry out proofs in what was then called fixed point theory and was later subsumed into denotational semantics, where it dropped out of sight.
And it implemented a logic defined by Dana Scott in a paper that he had withdrawn from publication, so you had to get an illicit copy.
(It [finally appeared](https://doi.org/10.1016/0304-3975(93)90095-B) in 1993.)

The reference manual was a volume entitled simply [*Edinburgh LCF*](https://link.springer.com/book/10.1007/3-540-09724-4).
It appeared in Springer's Lecture Notes series, volume 78; a catalogue listing the titles of every book in the series appeared on the inside covers, something they don't seem to do any more. Typical books of that era, it is a typescript, very likely generated by [nroff](https://en.wikipedia.org/wiki/Nroff).

The radical innovation of LCF was that its *metalanguage* (ML) would be a computationally complete programming language rather than some fixed set of commands.
This satisfied the twin goals of putting automation into the hands of the users 
while at the same time, through the proof kernel described [elsewhere]({% post_url 2022-01-05-LCF %}), preventing them from proving $0=1$.
Not that 0 or 1 was actually part of the formalism!

The first part of the book introduces ML, already described as "a general purpose programming language".
Not until page 62 do we reach the LCF formalism, called PPLAMBDA.
It's introduced by the example of proving that if $f(G)=G$ then $\mathop{\textrm fix}(f) \sqsubseteq G$.

<img src="/images/PPLAMBDA-proof.png" alt="PPLAMBDA proof of a small example" width="750"/>

I can remember feeling mixed emotions when reading the manual and experimenting with this system.
* On the one hand, amazement and elation at ML and its polymorphism.
Commonplace today in modern offshoots of ML, such as OCaml, and in languages such as Scala,
the idea of writing a single piece of code that simply worked for multiple types seemed a miracle.
* On the other hand, disappointment with PPLAMBDA, a tiny fragment of predicate logic with only implication, conjunction and universal quantifiers and the corresponding logical rules.
As types were interpreted by Scott domains, every type contained a "bottom" or "undefined" value, which was written `UU`.
That fragment of logic perhaps sufficed for the little examples floating around at the time, but it would be exceeded very quickly.


### Extending the logic

### Compilation for ML


(As told by Michael Gordon in
"From LCF to HOL: a short history",
*[Proof, Language, and Interaction: Essays in Honour of Robin Milner](https://mitpress.mit.edu/books/proof-language-and-interaction)* 169â€“185.
Quote on p. 170. Available for free [here](https://www.cl.cam.ac.uk/archive/mjcg/papers/HolHistory.pdf).)
